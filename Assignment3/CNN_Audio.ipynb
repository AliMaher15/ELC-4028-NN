{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITaSzDbZvD_3"
      },
      "source": [
        "Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "xagm99P8BsB6",
        "outputId": "1fe829c1-9661-43f1-f2c2-f299b742f438",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "qGiZAJeKGyV7",
        "outputId": "71141c9e-d115-4cb2-d233-de5f75d9a211",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: tensorflow-io in /usr/local/lib/python3.9/dist-packages (0.32.0)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem==0.32.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow-io) (0.32.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install tensorflow-io"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "6jlUf8k3vD_6"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "import tensorflow as tf \n",
        "import tensorflow_io as tfio\n",
        "from tensorflow import keras\n",
        "from keras import backend as k\n",
        "import time\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8B9Gh9PaIawq"
      },
      "source": [
        "# 1. Process Audio into Spectogram"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3liWIk8vD_-"
      },
      "source": [
        "a function that returns audio in numeric representation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "z3iDkeOvvD__"
      },
      "outputs": [],
      "source": [
        "def load_wav_16k_mono(filename):\n",
        "    # Load encoded wav file\n",
        "    file_contents = tf.io.read_file(filename)\n",
        "    # Decode wav (tensors by channels) \n",
        "    wav, sample_rate = tf.audio.decode_wav(file_contents, desired_channels=1)\n",
        "    # Removes trailing axis\n",
        "    wav = tf.squeeze(wav, axis=-1)\n",
        "    sample_rate = tf.cast(sample_rate, dtype=tf.int64)\n",
        "    # Goes from 44100Hz to 16000hz - amplitude of the audio signal\n",
        "    #wav = tfio.audio.resample(wav, rate_in=sample_rate, rate_out=16000)\n",
        "    return wav"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhqouUe-BklP"
      },
      "source": [
        "Read all audio files and sort"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "1f14-Y5NBklQ"
      },
      "outputs": [],
      "source": [
        "TRAIN = os.path.join('/content','drive','MyDrive','audio-data', 'Train')\n",
        "TEST = os.path.join('/content','drive','MyDrive','audio-data', 'Test')\n",
        "#TRAIN = os.path.join('audio-data', 'Train')\n",
        "#TEST = os.path.join('audio-data', 'Test')\n",
        "train = tf.data.Dataset.list_files(TRAIN+'/*.wav')\n",
        "train = sorted(list(train.as_numpy_iterator()))\n",
        "train = tf.data.Dataset.from_tensor_slices(train)\n",
        "test = tf.data.Dataset.list_files(TEST+'/*.wav')\n",
        "test = sorted(list(test.as_numpy_iterator()))\n",
        "test = tf.data.Dataset.from_tensor_slices(test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oL6VGLrKBklQ"
      },
      "source": [
        "Add Labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "FqnvMBIgBklR"
      },
      "outputs": [],
      "source": [
        "num_classes = 10\n",
        "iterations = 0\n",
        "i = 0\n",
        "train_label = []\n",
        "while iterations!=len(train):\n",
        "    iterations +=1\n",
        "    train_label.append(i)\n",
        "    i += 1\n",
        "    if i == num_classes :\n",
        "        i = 0\n",
        "train_label=keras.utils.to_categorical(train_label,num_classes)\n",
        "trainings = tf.data.Dataset.zip((train, tf.data.Dataset.from_tensor_slices(train_label)))\n",
        "#---------------------------------------------------------------#\n",
        "iterations = 0\n",
        "i = 0\n",
        "test_label=[]\n",
        "while iterations!=len(test):\n",
        "    iterations +=1\n",
        "    test_label.append(i)\n",
        "    i += 1\n",
        "    if i == num_classes :\n",
        "        i = 0\n",
        "test_label=keras.utils.to_categorical(test_label,num_classes)\n",
        "testings = tf.data.Dataset.zip((test, tf.data.Dataset.from_tensor_slices(test_label)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9wucjBYBklR"
      },
      "source": [
        "Build Preprocessing Function to get spectogram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "H1Uxr80iBklS"
      },
      "outputs": [],
      "source": [
        "def preprocess(file_path, label): \n",
        "    wav = load_wav_16k_mono(file_path)\n",
        "    #wav = wav[:48000]\n",
        "    #zero_padding = tf.zeros([48000] - tf.shape(wav), dtype=tf.float32)\n",
        "    #wav = tf.concat([zero_padding, wav],0)\n",
        "    spectrogram = tf.signal.stft(wav, frame_length=320, frame_step=32)\n",
        "    spectrogram = tf.abs(spectrogram)\n",
        "    spectrogram = tf.expand_dims(spectrogram, axis=2)\n",
        "    return spectrogram, label"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cq3zzxCPBklT"
      },
      "source": [
        "Convert all to Spectogram"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "iKKWiuGDBklT"
      },
      "outputs": [],
      "source": [
        "# train data\n",
        "x_train = trainings.map(preprocess)\n",
        "x_train = x_train.cache()\n",
        "x_train = x_train.shuffle(buffer_size=1000)\n",
        "x_train = x_train.batch(16) # 16 at a time\n",
        "x_train = x_train.prefetch(8)\n",
        "# test data\n",
        "x_test = testings.map(preprocess)\n",
        "x_test = x_test.cache()\n",
        "x_test = x_test.shuffle(buffer_size=1000)\n",
        "x_test = x_test.batch(16) # 16 at a time\n",
        "x_test = x_test.prefetch(8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NhvPPp2_BklU",
        "outputId": "42728afb-4977-4f75-f942-f1e3b8963306"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(16, 391, 257, 1)\n",
            "\n",
            " [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]] \n",
            "...\n"
          ]
        }
      ],
      "source": [
        "# test one batch\n",
        "samples, labels = x_train.as_numpy_iterator().next()\n",
        "print(samples.shape)\n",
        "print('\\n',labels[0:2],'\\n...')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pX1ZVQVBHtjW"
      },
      "source": [
        "# 2. CNN no Attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zGyNu1XvEAG"
      },
      "source": [
        "Design the CNN architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "VDmx4mx8BklV"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras import layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dgaH6t_XvEAG",
        "outputId": "f483ab3e-7f1c-4898-bd35-ad5902843168"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 389, 255, 32)      320       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 194, 127, 32)     0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 194, 127, 32)      0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 788416)            0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 32)                25229344  \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                330       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 25,229,994\n",
            "Trainable params: 25,229,994\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model=Sequential()\n",
        "input_shape = (391, 257, 1)\n",
        "model.add( layers.Conv2D(32,kernel_size=(3,3),activation='relu',input_shape=input_shape) )\n",
        "model.add( layers.MaxPooling2D(pool_size=(2,2)) )\n",
        "model.add( layers.Dropout(0.2) )\n",
        "model.add( layers.Flatten() )\n",
        "model.add( layers.Dense(32,activation='relu') )\n",
        "model.add( layers.Dense(num_classes,activation='softmax') )\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1HR8V-FSvEAH"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "4CRJsl0rBklW"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer=keras.optimizers.Adam(),\n",
        "              loss=keras.losses.categorical_crossentropy,\n",
        "              metrics=['accuracy']\n",
        "             )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fil5Jz7zvEAI",
        "outputId": "bc004203-e297-4996-f10f-516101506d77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "75/75 [==============================] - 57s 560ms/step - loss: 2.1039 - accuracy: 0.5250 - val_loss: 0.9418 - val_accuracy: 0.7400\n",
            "Epoch 2/15\n",
            "75/75 [==============================] - 4s 55ms/step - loss: 0.4593 - accuracy: 0.8783 - val_loss: 0.7764 - val_accuracy: 0.7967\n",
            "Epoch 3/15\n",
            "75/75 [==============================] - 4s 53ms/step - loss: 0.1701 - accuracy: 0.9558 - val_loss: 0.9367 - val_accuracy: 0.7933\n",
            "Epoch 4/15\n",
            "75/75 [==============================] - 4s 54ms/step - loss: 0.0881 - accuracy: 0.9775 - val_loss: 1.3154 - val_accuracy: 0.8100\n",
            "Epoch 5/15\n",
            "75/75 [==============================] - 4s 55ms/step - loss: 0.2319 - accuracy: 0.9433 - val_loss: 1.8162 - val_accuracy: 0.6867\n",
            "Epoch 6/15\n",
            "75/75 [==============================] - 4s 52ms/step - loss: 0.1002 - accuracy: 0.9817 - val_loss: 1.5322 - val_accuracy: 0.7700\n",
            "Epoch 7/15\n",
            "75/75 [==============================] - 4s 54ms/step - loss: 0.0171 - accuracy: 0.9992 - val_loss: 1.7880 - val_accuracy: 0.7633\n",
            "Epoch 8/15\n",
            "75/75 [==============================] - 4s 58ms/step - loss: 0.0306 - accuracy: 0.9958 - val_loss: 1.9709 - val_accuracy: 0.7400\n",
            "Epoch 9/15\n",
            "75/75 [==============================] - 4s 53ms/step - loss: 0.0417 - accuracy: 0.9892 - val_loss: 2.0498 - val_accuracy: 0.7633\n",
            "Epoch 10/15\n",
            "75/75 [==============================] - 4s 53ms/step - loss: 0.0075 - accuracy: 0.9992 - val_loss: 2.0850 - val_accuracy: 0.7700\n"
          ]
        }
      ],
      "source": [
        "early_stopping = EarlyStopping(monitor='accuracy', patience=3)\n",
        "tic=time.time()\n",
        "model.fit(x_train,\n",
        "          epochs=15,\n",
        "          verbose=1,\n",
        "          callbacks=[early_stopping],\n",
        "          validation_data=x_test\n",
        "          )\n",
        "toc=time.time()\n",
        "training_time=toc-tic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_6puCERJJVqY",
        "outputId": "92b624bd-bb0b-4918-d017-463ee8099e78"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19/19 [==============================] - 0s 9ms/step - loss: 2.0850 - accuracy: 0.7700\n",
            "Training Time = 95.6 s\n",
            "Testing Time = 310.3 ms\n",
            "Test Loss = 208.50 %:\n",
            "Test Accuracy = 77.00 %:\n"
          ]
        }
      ],
      "source": [
        "tic=time.time()\n",
        "test_loss, test_acc = model.evaluate(x_test)\n",
        "toc=time.time()\n",
        "test_time=toc-tic\n",
        "print(\"Training Time = {} s\".format(np.round(training_time, 1)))\n",
        "print(\"Testing Time = {} ms\".format(np.round(test_time*1000, 1)))\n",
        "print('Test Loss = {:.2f} %:'.format(np.round(test_loss, 3)*100))\n",
        "print('Test Accuracy = {:.2f} %:'.format(np.round(test_acc, 3)*100))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NnjGStQcHorX"
      },
      "source": [
        "# 3. CNN with Attention"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9ryVXwXH7au"
      },
      "source": [
        "Design the CNN architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7J2O7FcDH6d7",
        "outputId": "e1fbbfbe-91d6-432c-8473-8f1adcece48c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 391, 257, 1  0           []                               \n",
            "                                )]                                                                \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)              (None, 389, 255, 32  320         ['input_1[0][0]']                \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " max_pooling2d_1 (MaxPooling2D)  (None, 194, 127, 32  0          ['conv2d_1[0][0]']               \n",
            "                                )                                                                 \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)              (None, 194, 127, 1)  289         ['max_pooling2d_1[0][0]']        \n",
            "                                                                                                  \n",
            " multiply (Multiply)            (None, 194, 127, 32  0           ['max_pooling2d_1[0][0]',        \n",
            "                                )                                 'conv2d_2[0][0]']               \n",
            "                                                                                                  \n",
            " max_pooling2d_2 (MaxPooling2D)  (None, 97, 63, 32)  0           ['multiply[0][0]']               \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 97, 63, 32)   0           ['max_pooling2d_2[0][0]']        \n",
            "                                                                                                  \n",
            " flatten_1 (Flatten)            (None, 195552)       0           ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 32)           6257696     ['flatten_1[0][0]']              \n",
            "                                                                                                  \n",
            " dense_3 (Dense)                (None, 10)           330         ['dense_2[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 6,258,635\n",
            "Trainable params: 6,258,635\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "inputs = layers.Input(shape=input_shape)\n",
        "\n",
        "conv1 = layers.Conv2D(32,kernel_size=(3,3),activation='relu')(inputs)\n",
        "pool1 = layers.MaxPool2D(pool_size=(2,2))(conv1)\n",
        "#Attention1\n",
        "attention_conv1 = layers.Conv2D(1, (3,3), padding='same', activation='sigmoid')(pool1)\n",
        "attention_mul1 = layers.Multiply()([pool1, attention_conv1])\n",
        "pool2 = layers.MaxPool2D(pool_size=(2,2))(attention_mul1)\n",
        "##########\n",
        "drop1 = layers.Dropout(0.2)(pool2)\n",
        "flatten2 = layers.Flatten()(drop1)\n",
        "dense2 = layers.Dense(32,activation='relu')(flatten2)\n",
        "dense3 = layers.Dense(num_classes,activation='softmax')(dense2)\n",
        "\n",
        "modelAtt = keras.Model(inputs=inputs, outputs=dense3)\n",
        "\n",
        "modelAtt.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dwXMnyAiIG1T"
      },
      "source": [
        "Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "8ejqCmZ1IIKk"
      },
      "outputs": [],
      "source": [
        "modelAtt.compile(optimizer=keras.optimizers.Adam(),\n",
        "              loss= keras.losses.CategoricalCrossentropy(),\n",
        "              metrics=['accuracy']\n",
        "             )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4hEzys7IKNS",
        "outputId": "bab5e8cd-e791-464d-c406-af833177afa7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "75/75 [==============================] - 7s 63ms/step - loss: 1.4784 - accuracy: 0.5558 - val_loss: 0.9242 - val_accuracy: 0.7300\n",
            "Epoch 2/15\n",
            "75/75 [==============================] - 5s 64ms/step - loss: 0.5059 - accuracy: 0.8675 - val_loss: 0.8350 - val_accuracy: 0.7700\n",
            "Epoch 3/15\n",
            "75/75 [==============================] - 5s 65ms/step - loss: 0.2713 - accuracy: 0.9375 - val_loss: 0.8104 - val_accuracy: 0.7467\n",
            "Epoch 4/15\n",
            "75/75 [==============================] - 5s 63ms/step - loss: 0.1723 - accuracy: 0.9633 - val_loss: 1.5070 - val_accuracy: 0.7867\n",
            "Epoch 5/15\n",
            "75/75 [==============================] - 5s 60ms/step - loss: 0.3095 - accuracy: 0.9375 - val_loss: 1.4172 - val_accuracy: 0.7700\n",
            "Epoch 6/15\n",
            "75/75 [==============================] - 5s 63ms/step - loss: 0.1313 - accuracy: 0.9742 - val_loss: 1.6753 - val_accuracy: 0.7900\n",
            "Epoch 7/15\n",
            "75/75 [==============================] - 5s 62ms/step - loss: 0.1480 - accuracy: 0.9733 - val_loss: 1.4575 - val_accuracy: 0.7933\n",
            "Epoch 8/15\n",
            "75/75 [==============================] - 5s 64ms/step - loss: 0.0407 - accuracy: 0.9917 - val_loss: 1.5516 - val_accuracy: 0.7967\n",
            "Epoch 9/15\n",
            "75/75 [==============================] - 5s 65ms/step - loss: 0.0250 - accuracy: 0.9992 - val_loss: 1.6429 - val_accuracy: 0.8233\n",
            "Epoch 10/15\n",
            "75/75 [==============================] - 5s 65ms/step - loss: 0.0158 - accuracy: 1.0000 - val_loss: 1.6056 - val_accuracy: 0.8333\n",
            "Epoch 11/15\n",
            "75/75 [==============================] - 5s 68ms/step - loss: 0.0116 - accuracy: 1.0000 - val_loss: 1.6566 - val_accuracy: 0.8167\n",
            "Epoch 12/15\n",
            "75/75 [==============================] - 5s 66ms/step - loss: 0.0084 - accuracy: 1.0000 - val_loss: 2.0003 - val_accuracy: 0.8000\n",
            "Epoch 13/15\n",
            "75/75 [==============================] - 5s 66ms/step - loss: 0.0062 - accuracy: 1.0000 - val_loss: 2.0579 - val_accuracy: 0.8133\n"
          ]
        }
      ],
      "source": [
        "tic=time.time()\n",
        "modelAtt.fit(x_train,\n",
        "          epochs=15,\n",
        "          verbose=1,\n",
        "          callbacks=[early_stopping],\n",
        "          validation_data=x_test\n",
        "          )\n",
        "toc=time.time()\n",
        "training_time=toc-tic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GXj-H100JpsN",
        "outputId": "2551d1e0-ebc6-4be6-d338-ed55513e863f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "19/19 [==============================] - 0s 10ms/step - loss: 2.0579 - accuracy: 0.8133\n",
            "Training Time = 69.2 s\n",
            "Testing Time = 317.6 ms\n",
            "Test Loss = 205.80 %:\n",
            "Test Accuracy = 81.30 %:\n"
          ]
        }
      ],
      "source": [
        "tic=time.time()\n",
        "test_loss, test_acc = modelAtt.evaluate(x_test)\n",
        "toc=time.time()\n",
        "test_time=toc-tic\n",
        "print(\"Training Time = {} s\".format(np.round(training_time, 1)))\n",
        "print(\"Testing Time = {} ms\".format(np.round(test_time*1000, 1)))\n",
        "print('Test Loss = {:.2f} %:'.format(np.round(test_loss, 3)*100))\n",
        "print('Test Accuracy = {:.2f} %:'.format(np.round(test_acc, 3)*100))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}