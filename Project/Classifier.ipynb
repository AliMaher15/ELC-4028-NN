{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xr0pMIcD1RAw"
      },
      "source": [
        "# 1. Import Libraries and Set Directory\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITaSzDbZvD_3"
      },
      "source": [
        "Import Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "xagm99P8BsB6"
      },
      "outputs": [],
      "source": [
        "is_drive = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "x6NxANuJ1RA0"
      },
      "outputs": [],
      "source": [
        "if is_drive==1 :\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "6jlUf8k3vD_6"
      },
      "outputs": [],
      "source": [
        "# directory management\n",
        "import os\n",
        "from glob import glob\n",
        "# regular imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# imports for NN\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import time"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "XB2OwBWH1RA5"
      },
      "source": [
        "# 2. Load Dataset\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "1f14-Y5NBklQ"
      },
      "outputs": [],
      "source": [
        "# Spectogram Path\n",
        "if is_drive==1 :   \n",
        "    TRAIN_DIR = \"/content/drive/MyDrive/spectogram-dataset/Train/\"\n",
        "    TEST_DIR = \"/content/drive/MyDrive/spectogram-dataset/Test/\"\n",
        "    AE_SPECTROGRAMS_SAVE_DIR1 = \"/content/drive/MyDrive/autoencoder-generations/Generated-Test/\"\n",
        "    E_SPECTROGRAMS_SAVE_DIR1 = \"/content/drive/MyDrive/autoencoder-generations/Compressed-Test/\"\n",
        "    AE_SPECTROGRAMS_SAVE_DIR2 = \"/content/drive/MyDrive/autoencoder-generations/Generated-Train/\"\n",
        "    E_SPECTROGRAMS_SAVE_DIR2 = \"/content/drive/MyDrive/autoencoder-generations/Compressed-Train/\"\n",
        "else :\n",
        "    TRAIN_DIR = \"../Project/spectogram-dataset/Train/\"\n",
        "    TEST_DIR = \"../Project/spectogram-dataset/Test/\"\n",
        "    AE_SPECTROGRAMS_SAVE_DIR1 = \"../Project/autoencoder-generations/Generated-Test/\"\n",
        "    E_SPECTROGRAMS_SAVE_DIR1 = \"../Project/autoencoder-generations/Compressed-Test/\"\n",
        "    AE_SPECTROGRAMS_SAVE_DIR2 = \"../Project/autoencoder-generations/Generated-Train/\"\n",
        "    E_SPECTROGRAMS_SAVE_DIR2 = \"../Project/autoencoder-generations/Compressed-Train/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-qUmHgZk1RA5"
      },
      "outputs": [],
      "source": [
        "def load_fsdd(the_path):\n",
        "    x_train = []\n",
        "    for root, _, file_names in os.walk(the_path):\n",
        "        for file_name in file_names:\n",
        "            file_path = os.path.join(root, file_name)\n",
        "            spectrogram = np.load(file_path) # (n_bins, n_frames)\n",
        "            x_train.append(spectrogram)\n",
        "    x_train = np.array(x_train)        # -> (n_samples, n_bins, n_frames)\n",
        "    x_train = x_train[..., np.newaxis] # -> (1200, 800, 32, 1)\n",
        "    \n",
        "    return x_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "iKKWiuGDBklT"
      },
      "outputs": [],
      "source": [
        "x_train_raw = load_fsdd(TRAIN_DIR)\n",
        "x_test_raw  = load_fsdd(TEST_DIR)\n",
        "\n",
        "AE_test = load_fsdd(AE_SPECTROGRAMS_SAVE_DIR1)\n",
        "E_test = load_fsdd(E_SPECTROGRAMS_SAVE_DIR1)\n",
        "\n",
        "AE_train = load_fsdd(AE_SPECTROGRAMS_SAVE_DIR2)\n",
        "E_train = load_fsdd(E_SPECTROGRAMS_SAVE_DIR2)\n",
        "\n",
        "AE_test = AE_test[:, :, :, :, 0]\n",
        "AE_train = AE_train[:, :, :, :, 0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "x_train_raw (1200, 160, 84, 1)\n",
            "x_test_raw (300, 160, 84, 1)\n",
            "\n",
            "\n",
            "AE_test (300, 160, 84, 1)\n",
            "E_test (300, 16, 1)\n",
            "\n",
            "\n",
            "AE_train (1200, 160, 84, 1)\n",
            "E_train (1200, 16, 1)\n"
          ]
        }
      ],
      "source": [
        "print(\"x_train_raw\" , x_train_raw.shape)\n",
        "print(\"x_test_raw\" , x_test_raw.shape)\n",
        "print(\"\\n\")\n",
        "print(\"AE_test\" , AE_test.shape)\n",
        "print(\"E_test\" , E_test.shape)\n",
        "print(\"\\n\")\n",
        "print(\"AE_train\" , AE_train.shape)\n",
        "print(\"E_train\" , E_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "num_classes = 10\n",
        "iterations = 0\n",
        "i = 0\n",
        "y_train = []\n",
        "while iterations!=len(x_train_raw):\n",
        "    iterations +=1\n",
        "    y_train.append(i)\n",
        "    i += 1\n",
        "    if i == num_classes :\n",
        "        i = 0\n",
        "y_train = np.array(y_train)\n",
        "#---------------------------------------------------------------#\n",
        "iterations = 0\n",
        "i = 0\n",
        "y_test =[]\n",
        "while iterations!=len(x_test_raw):\n",
        "    iterations +=1\n",
        "    y_test.append(i)\n",
        "    i += 1\n",
        "    if i == num_classes :\n",
        "        i = 0\n",
        "y_test = np.array(y_test)\n",
        "\n",
        "y_train=keras.utils.to_categorical(y_train,num_classes)\n",
        "y_test =keras.utils.to_categorical(y_test,num_classes)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]\n",
            "[0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n"
          ]
        }
      ],
      "source": [
        "print(y_train[0])\n",
        "print(y_train[5])\n",
        "print(y_test[9])"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 3. Create Classifer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "import keras\n",
        "from keras import layers\n",
        "from keras import Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "One of the dimensions in the output is <= 0 due to downsampling in conv2d_8. Consider increasing the input size. Received input shape [None, 1, 1, 4] which would produce output shape with a zero or negative value in a dimension.",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[22], line 10\u001b[0m\n\u001b[0;32m      7\u001b[0m model4\u001b[39m.\u001b[39madd(layers\u001b[39m.\u001b[39mAveragePooling2D(pool_size\u001b[39m=\u001b[39m(\u001b[39m2\u001b[39m, \u001b[39m2\u001b[39m), strides\u001b[39m=\u001b[39m(\u001b[39m2\u001b[39m, \u001b[39m2\u001b[39m), padding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mvalid\u001b[39m\u001b[39m'\u001b[39m))\n\u001b[0;32m      9\u001b[0m \u001b[39m# Convolutional layer 2\u001b[39;00m\n\u001b[1;32m---> 10\u001b[0m model4\u001b[39m.\u001b[39;49madd(layers\u001b[39m.\u001b[39;49mConv2D(\u001b[39m32\u001b[39;49m, (\u001b[39m5\u001b[39;49m, \u001b[39m5\u001b[39;49m), activation\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mtanh\u001b[39;49m\u001b[39m'\u001b[39;49m, padding\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mvalid\u001b[39;49m\u001b[39m'\u001b[39;49m))\n\u001b[0;32m     12\u001b[0m \u001b[39m# Average pooling layer 2\u001b[39;00m\n\u001b[0;32m     13\u001b[0m model4\u001b[39m.\u001b[39madd(layers\u001b[39m.\u001b[39mAveragePooling2D(pool_size\u001b[39m=\u001b[39m(\u001b[39m2\u001b[39m, \u001b[39m2\u001b[39m), strides\u001b[39m=\u001b[39m(\u001b[39m2\u001b[39m, \u001b[39m2\u001b[39m), padding\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mvalid\u001b[39m\u001b[39m'\u001b[39m))\n",
            "File \u001b[1;32mc:\\Users\\Ali\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tensorflow\\python\\trackable\\base.py:205\u001b[0m, in \u001b[0;36mno_automatic_dependency_tracking.<locals>._method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    203\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n\u001b[0;32m    204\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 205\u001b[0m   result \u001b[39m=\u001b[39m method(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    206\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m    207\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_self_setattr_tracking \u001b[39m=\u001b[39m previous_value  \u001b[39m# pylint: disable=protected-access\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\Ali\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[1;32mc:\\Users\\Ali\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\layers\\convolutional\\base_conv.py:354\u001b[0m, in \u001b[0;36mConv.compute_output_shape\u001b[1;34m(self, input_shape)\u001b[0m\n\u001b[0;32m    347\u001b[0m         \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39mTensorShape(\n\u001b[0;32m    348\u001b[0m             input_shape[:batch_rank]\n\u001b[0;32m    349\u001b[0m             \u001b[39m+\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfilters]\n\u001b[0;32m    350\u001b[0m             \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_spatial_output_shape(input_shape[batch_rank \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m :])\n\u001b[0;32m    351\u001b[0m         )\n\u001b[0;32m    353\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mValueError\u001b[39;00m:\n\u001b[1;32m--> 354\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    355\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mOne of the dimensions in the output is <= 0 \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    356\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdue to downsampling in \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname\u001b[39m}\u001b[39;00m\u001b[39m. Consider \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    357\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mincreasing the input size. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    358\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mReceived input shape \u001b[39m\u001b[39m{\u001b[39;00minput_shape\u001b[39m}\u001b[39;00m\u001b[39m which would produce \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    359\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39moutput shape with a zero or negative value in a \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    360\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdimension.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    361\u001b[0m     )\n",
            "\u001b[1;31mValueError\u001b[0m: One of the dimensions in the output is <= 0 due to downsampling in conv2d_8. Consider increasing the input size. Received input shape [None, 1, 1, 4] which would produce output shape with a zero or negative value in a dimension."
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "model4 = keras.Sequential()\n",
        "\n",
        "# Convolutional layer 1\n",
        "model4.add(layers.Conv2D(4, (3, 3), activation='tanh', input_shape=(16, 1, 1), padding='valid'))\n",
        "\n",
        "# Average pooling layer 1\n",
        "model4.add(layers.AveragePooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'))\n",
        "\n",
        "# Convolutional layer 2\n",
        "model4.add(layers.Conv2D(32, (5, 5), activation='tanh', padding='valid'))\n",
        "\n",
        "# Average pooling layer 2\n",
        "model4.add(layers.AveragePooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid'))\n",
        "\n",
        "# Flatten layer\n",
        "model4.add(layers.Flatten())\n",
        "\n",
        "# Fully connected layer 1\n",
        "model4.add(layers.Dense(120, activation='tanh'))\n",
        "\n",
        "# Fully connected layer 2\n",
        "model4.add(layers.Dense(84, activation='tanh'))\n",
        "\n",
        "# Output layer\n",
        "model4.add(layers.Dense(10, activation='softmax'))\n",
        "\n",
        "model4.summary() "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.6"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
